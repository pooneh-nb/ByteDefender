{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "0dQdJIhRFkC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "EDZUQudK0cG7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm train.py"
      ],
      "metadata": {
        "id": "SLeAAv8uCOJY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run 3 times to upload model.py, seqio_utils.py, train.py, train.tfrecord\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "collapsed": true,
        "id": "877A-48S0mhm",
        "outputId": "3931cd89-aa19-4edf-eccf-b09f5cb3ba6f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35148437-78e4-4a36-84d0-c5afc8c05218\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-35148437-78e4-4a36-84d0-c5afc8c05218\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.py to train.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train.py': b'\"\"\"Bianry for training bytecodes classifier transformer.\"\"\"\\n\\nimport functools\\nimport logging\\nfrom typing import Any, Callable, Sequence, Type\\n\\nimport chex\\nfrom clu import metric_writers\\nfrom clu import metrics\\nfrom clu import periodic_actions\\nimport flax\\nimport flax.linen as nn\\nfrom flax.training import train_state\\nimport jax\\nfrom jax.experimental import mesh_utils\\nimport jax.numpy as jnp\\nimport ml_collections\\nimport numpy as np\\nimport optax\\nfrom orbax import checkpoint as orbax_checkpoint\\n\\nimport model\\nimport seqio_utils\\n\\n\\nLearningRateSchedule = Callable[[chex.Numeric], chex.Numeric]\\n\\n\\nclass Config(ml_collections.ConfigDict):\\n  \"\"\"Configuration for training bytecodes classifier transformer.\"\"\"\\n\\n  model_name: str = \\'\\'\\n  seed: int = 42\\n\\n  num_train_steps: int = 1_000\\n  initial_step: int = 1\\n  log_loss_every_steps = 25\\n  eval_every_steps = 250\\n  checkpoint_every_steps = 1_000\\n\\n  learning_rate: float = 0.001\\n  lr_warmup_steps: int = 100\\n  lr_decay_steps: int = -1\\n\\n  per_device_batch_size: int = 16\\n  train_tfrecord_path: str = \\'\\'\\n  test_tfrecord_path: str | None = None\\n  max_vocab_size: int = 256\\n  seqlen: int = 1024\\n\\n  num_layers: int = 6\\n  num_heads: int = 4\\n  embed_dim: int = 128\\n  transformer_mlp_dim: int = 512\\n  conv_layers: int | None = None\\n\\n  workdir: str = \\'\\'\\n  checkpoint_dir: str | None = None\\n\\n\\nclass ClassifierConfig(Config):\\n  \"\"\"Configuration for training the classifier model specifically.\"\"\"\\n\\n  classifier_mlp_dim: int = 128\\n\\n\\ndef TrainClassifier(\\n    config: ClassifierConfig, allow_duplicate_tasks: bool = False\\n):\\n  \"\"\"Trains a bytecodes classifier transformer.\"\"\"\\n  logging.info(\\'Training with config: %s\\', config)\\n\\n  try:\\n    seqio_utils.AddClassifierTask(\\n        train_tfrecord_path=config.train_tfrecord_path,\\n        test_tfrecord_path=config.test_tfrecord_path\\n        if hasattr(config, \\'test_tfrecord_path\\')\\n        else None,\\n        max_vocab_size=config.max_vocab_size,\\n        max_seqlen=config.seqlen,\\n    )\\n  except ValueError as e:  # Task already exists.\\n    # Allow duplicate tasks in Colab.\\n    if (\\n        allow_duplicate_tasks\\n        and \\'Attempting to register duplicate provider\\' in str(e)\\n    ):\\n      pass\\n    else:\\n      raise e\\n  logging.info(\\'Device count: %d\\', jax.device_count())\\n  global_batch_size = config.per_device_batch_size * jax.device_count()\\n  logging.info(\\'Using global batch size: %d\\', global_batch_size)\\n\\n  train_ds = seqio_utils.ClassifierTrainDataset(global_batch_size, config.seed)\\n  train_ds = train_ds.shard(\\n      num_shards=jax.process_count(), index=jax.process_index()\\n  )\\n  train_ds_iter = iter(train_ds)\\n\\n  if (\\n      hasattr(config, \\'test_tfrecord_path\\')\\n      and config.test_tfrecord_path is not None\\n  ):\\n    test_ds = seqio_utils.ClassifierTestDataset(global_batch_size, config.seed)\\n    test_ds = test_ds.shard(\\n        num_shards=jax.process_count(), index=jax.process_index()\\n    )\\n  else:\\n    test_ds = None\\n\\n  mesh, data_sharding, data_spec, var_sharding, var_spec = _CreateMesh()\\n\\n  # Learning rate schedule.\\n  learning_rate_fn = functools.partial(LearningRate, config=config)\\n\\n  # Create train state.\\n  logging.info(\\'Using seed: %d\\', config.seed)\\n  rng = jax.random.PRNGKey(config.seed)\\n  state = _CreateTrainState(\\n      model.Classifier(\\n          vocab_size=config.max_vocab_size,\\n          embed_dim=config.embed_dim,\\n          seqlen=config.seqlen,\\n          num_layers=config.num_layers,\\n          num_heads=config.num_heads,\\n          tfrmr_hidden_dim=config.transformer_mlp_dim,\\n          cls_hidden_dim=config.classifier_mlp_dim,\\n          conv_layers=(\\n              config.conv_layers if hasattr(config, \\'conv_layers\\') else None\\n          ),\\n      ),\\n      rng,\\n      input_shape=(config.per_device_batch_size, config.seqlen),\\n      learning_rate_fn=learning_rate_fn,\\n      initial_step=config.initial_step,\\n  )\\n  initial_step = int(state.step)\\n  logging.info(\\n      \\'Total parameters: %d\\',\\n      sum(np.prod(x.shape) for x in jax.tree.leaves(state.params))\\n  )\\n\\n  checkpoint_manager, state = _CreateCheckpointManager(config, state)\\n\\n  train_step = _CreateParallelStep(\\n      functools.partial(\\n          _TrainStep,\\n          learning_rate_fn=learning_rate_fn,\\n          compute_loss_fn=_BinaryCrossEntropyLoss,\\n          metrics_cls=ClassifierTrainMetrics,\\n      ),\\n      mesh,\\n      data_sharding,\\n      data_spec,\\n      var_sharding,\\n      var_spec,\\n  )\\n  eval_step = _CreateParallelStep(\\n      _ClassifierEvalStep,\\n      mesh,\\n      data_sharding,\\n      data_spec,\\n      var_sharding,\\n      var_spec,\\n  )\\n\\n  train_metrics = None\\n  writer = metric_writers.create_default_writer(\\n      config.workdir,\\n      just_logging=jax.process_index() > 0,\\n  )\\n  report_progress = periodic_actions.ReportProgress(\\n      num_train_steps=config.num_train_steps, writer=writer\\n  )\\n  hooks = []\\n  if jax.process_index() == 0:\\n    hooks.append(report_progress)\\n\\n  for step in range(initial_step, config.num_train_steps + 1):\\n    assert step == state.step\\n    if step == 1:\\n      writer.write_hparams(dict(config))\\n    with mesh:\\n      with jax.profiler.StepTraceAnnotation(\\'train\\', step_num=step):\\n        # Cycle training data for as long as it takes to complete training\\n        # steps.\\n        try:\\n          batch = next(train_ds_iter)\\n        except StopIteration:\\n          train_ds_iter = iter(train_ds)\\n          batch = next(train_ds_iter)\\n\\n        # logging.info(\\'No. FP examples: %s\\', np.sum(batch[\\'label\\']))\\n        x = jnp.array(batch[\\'bytecodes\\'])\\n        y = jnp.array(batch[\\'label\\'])\\n        state, metrics_update = train_step(state, x, y)\\n      train_metrics = (\\n          metrics_update\\n          if train_metrics is None\\n          else train_metrics.merge(metrics_update)\\n      )\\n\\n      for h in hooks:\\n        h(step)\\n\\n      # Checkpoint.\\n      if (\\n          hasattr(config, \\'checkpoint_dir\\')\\n          and config.checkpoint_dir is not None\\n      ) and (\\n          step % config.checkpoint_every_steps == 0\\n          or step == config.num_train_steps\\n      ):\\n        assert checkpoint_manager is not None\\n        with report_progress.timed(\\'checkpoint\\'):\\n          checkpoint_manager.save(\\n              step,\\n              items=dict(\\n                  train_state=jax.tree.map(np.array, state),\\n              ),\\n          )\\n      # Flush train metrics.\\n      if (\\n          step % config.log_loss_every_steps == 0\\n          or step == config.num_train_steps\\n      ):\\n        writer.write_scalars(step, train_metrics.compute())\\n        train_metrics = None\\n      # Evaluate on test set.\\n      if (\\n          hasattr(config, \\'test_tfrecord_path\\')\\n          and config.test_tfrecord_path is not None\\n      ) and (\\n          step % config.eval_every_steps == 0 or step == config.num_train_steps\\n      ):\\n        assert test_ds is not None\\n        with report_progress.timed(\\'eval\\'):\\n          eval_metrics = None\\n          for batch in iter(test_ds):\\n            x = jnp.array(batch[\\'bytecodes\\'])\\n            y = jnp.array(batch[\\'label\\'])\\n            _, metrics_update = eval_step(state, x, y)\\n            eval_metrics = (\\n                metrics_update\\n                if eval_metrics is None\\n                else eval_metrics.merge(metrics_update)\\n            )\\n        if eval_metrics is not None:\\n          writer.write_scalars(step, eval_metrics.compute())\\n  writer.flush()\\n\\n\\ndef _CreateMesh() -> tuple[\\n    jax.sharding.Mesh,\\n    jax.sharding.NamedSharding,\\n    jax.sharding.PartitionSpec,\\n    jax.sharding.NamedSharding,\\n    jax.sharding.PartitionSpec,\\n]:\\n  \"\"\"Create device mesh for data sharding.\"\"\"\\n  # Use multiple devices if available for data parallelism.\\n  device_mesh = mesh_utils.create_device_mesh(\\n      mesh_shape=(jax.device_count(),),\\n      devices=jax.devices(),\\n      allow_split_physical_axes=True,\\n  )\\n  mesh = jax.sharding.Mesh(device_mesh, (\\'devices\\',))\\n  # Shards the batch axis across all devices.\\n  data_spec = jax.sharding.PartitionSpec(\\'devices\\')\\n  data_sharding = jax.sharding.NamedSharding(mesh, data_spec)\\n  # The model parameters are not sharded, instead they are replicated across\\n  # all devices and gradients are averaged across all devices.\\n  var_spec = jax.sharding.PartitionSpec()\\n  var_sharding = jax.sharding.NamedSharding(mesh, var_spec)\\n  return mesh, data_sharding, data_spec, var_sharding, var_spec\\n\\n\\nclass TrainState(train_state.TrainState):\\n  step: int\\n  params: Any\\n  opt_state: optax.OptState\\n\\n\\ndef _CreateCheckpointManager(\\n    config: Config,\\n    state: TrainState,\\n) -> tuple[orbax_checkpoint.CheckpointManager | None, TrainState]:\\n  \"\"\"Create a checkpoint manager for the training state.\"\"\"\\n  if not hasattr(config, \\'checkpoint_dir\\') or config.checkpoint_dir is None:\\n    return None, state\\n  checkpointers = dict(train_state=orbax_checkpoint.PyTreeCheckpointer())\\n  checkpoint_manager = orbax_checkpoint.CheckpointManager(\\n      config.checkpoint_dir,\\n      checkpointers=checkpointers,\\n      options=orbax_checkpoint.CheckpointManagerOptions(create=True),\\n  )\\n  checkpoint_state = dict(train_state=state)\\n  if checkpoint_manager.latest_step() is not None:\\n    state = checkpoint_manager.restore(\\n        checkpoint_manager.latest_step(), items=checkpoint_state\\n    )\\n  return checkpoint_manager, state\\n\\n\\ndef _GetPredictedLabels(logits: jnp.ndarray) -> jnp.ndarray:\\n  if logits.shape[-1] == 1:\\n    return (logits.squeeze(-1) >= 0.5).astype(jnp.float32)\\n  return jnp.argmax(logits, axis=-1, keepdims=False).astype(jnp.float32)\\n\\n\\n@flax.struct.dataclass\\nclass ClassifierAccuracy(metrics.Accuracy):\\n\\n  @classmethod\\n  def from_model_output(\\n      cls, *, logits: jnp.ndarray, labels: jnp.ndarray, **kwargs\\n  ):\\n    metric = metrics.Average.from_model_output(\\n        values=(_GetPredictedLabels(logits) == labels).astype(jnp.float32),\\n        **kwargs,\\n    )\\n    return cls(**vars(metric))  # cls(metrics) doesn\\'t work for a dataclass\\n\\n\\n@flax.struct.dataclass\\nclass Recall(metrics.Metric):\\n  \"\"\"Custom binary recall metric.\"\"\"\\n  confusion_matrix: jnp.ndarray\\n\\n  @classmethod\\n  def from_model_output(cls, *, logits: jnp.ndarray, labels: jnp.ndarray, **_):\\n    return cls(\\n        confusion_matrix=_ConfusionMatrix(labels, _GetPredictedLabels(logits)),\\n    )\\n\\n  def compute(self):\\n    return super().compute()[1]\\n\\n  def merge(self, other: \\'Recall\\') -> \\'Recall\\':\\n    return type(self)(\\n        confusion_matrix=self.confusion_matrix + other.confusion_matrix)\\n\\n  def compute(self):\\n    true_positives = jnp.diag(self.confusion_matrix)\\n    denominator = jnp.sum(self.confusion_matrix, axis=1)\\n    precision = _DivideNoNaN(true_positives, denominator)\\n    return precision[1]\\n\\n\\ndef _ConfusionMatrix(labels: jnp.ndarray, logits: jnp.ndarray) -> jnp.ndarray:\\n  return jnp.histogram2d(\\n      labels.ravel(),\\n      logits.ravel(),\\n      bins=jnp.arange(3),\\n  )[0]\\n\\ndef _DivideNoNaN(x: jnp.ndarray, y: jnp.ndarray) -> jnp.ndarray:\\n  dtype = jnp.result_type(x, y)\\n  y_is_zero = jnp.equal(y, 0.)\\n  div = jnp.divide(x, jnp.where(y_is_zero, jnp.ones((), dtype=dtype), y))\\n  return jnp.where(y_is_zero, jnp.zeros((), dtype=dtype), div)\\n\\n\\n@flax.struct.dataclass\\nclass Precision(metrics.Metric):\\n  \"\"\"Custom binary precision metric.\"\"\"\\n  confusion_matrix: jnp.ndarray\\n\\n  @classmethod\\n  def from_model_output(cls, *, logits: jnp.ndarray, labels: jnp.ndarray, **_):\\n    return cls(\\n        confusion_matrix=_ConfusionMatrix(labels, _GetPredictedLabels(logits)),\\n    )\\n\\n  def merge(self, other: \\'Precision\\') -> \\'Precision\\':\\n    return type(self)(\\n        confusion_matrix=self.confusion_matrix + other.confusion_matrix)\\n\\n  def compute(self):\\n    true_positives = jnp.diag(self.confusion_matrix)\\n    false_positives = jnp.sum(self.confusion_matrix, axis=0) - true_positives\\n    precision = _DivideNoNaN(true_positives, true_positives + false_positives)\\n    return precision[1]\\n\\n\\n@flax.struct.dataclass\\nclass ClassifierTrainMetrics(metrics.Collection):\\n  learning_rate: metrics.LastValue.from_output(\\'learning_rate\\')\\n  train_loss: metrics.Average.from_output(\\'loss\\')\\n  train_std: metrics.Std.from_output(\\'loss\\')\\n  train_accuracy: ClassifierAccuracy\\n  train_recall: Recall\\n  train_precision: Precision\\n\\n\\n@flax.struct.dataclass\\nclass EvalMetrics(metrics.Collection):\\n  eval_accuracy: ClassifierAccuracy\\n  eval_recall: Recall\\n  eval_precision: Precision\\n  eval_loss: metrics.Average.from_output(\\'loss\\')\\n  eval_std: metrics.Std.from_output(\\'loss\\')\\n\\n\\ndef _CreateTrainState(\\n    mdl: nn.Module,\\n    rng: jnp.ndarray,\\n    input_shape: Sequence[int],\\n    learning_rate_fn: LearningRateSchedule,\\n    initial_step: int,\\n) -> TrainState:\\n  \"\"\"Initializes the model, optimizer, and train state.\"\"\"\\n  variables = mdl.init(rng, np.zeros(input_shape, dtype=np.int64))\\n  params = variables[\\'params\\']\\n  tx = optax.adam(learning_rate=learning_rate_fn)\\n  state = TrainState.create(\\n      apply_fn=mdl.apply,\\n      params=params,\\n      tx=tx,\\n  )\\n  state = state.replace(step=initial_step)\\n  return state\\n\\n\\ndef LearningRate(step: int, *, config: Config) -> float | jnp.ndarray:\\n  warmup_steps = jnp.maximum(config.lr_warmup_steps, 1)\\n  warmup = jnp.minimum(1.0, step / warmup_steps)\\n  # Cosine decay.\\n  ratio = jnp.maximum(0.0, step - config.lr_warmup_steps)\\n  decay_steps = jax.lax.cond(\\n      config.lr_decay_steps > 0,\\n      lambda: float(config.lr_decay_steps),\\n      lambda: float(\\'inf\\'),\\n  )\\n  ratio /= jnp.maximum(1.0, decay_steps)\\n  mult = 0.5 * (1.0 + jnp.cos(jnp.pi * ratio))\\n  return warmup * mult * config.learning_rate\\n\\n\\ndef _CreateParallelStep(\\n    train_step_fn: Callable,  # pylint: disable=g-bare-generic\\n    mesh: jax.sharding.Mesh,\\n    data_sharding: jax.sharding.NamedSharding,\\n    data_spec: jax.sharding.PartitionSpec,\\n    var_sharding: jax.sharding.NamedSharding,\\n    var_spec: jax.sharding.PartitionSpec,\\n) -> Callable:  # pylint: disable=g-bare-generic\\n  \"\"\"Create the train step function for data parallelism.\"\"\"\\n  train_step = jax.experimental.shard_map.shard_map(\\n      train_step_fn,\\n      mesh=mesh,\\n      in_specs=(var_spec, data_spec, data_spec),\\n      out_specs=(var_spec, var_spec),\\n      check_rep=False,\\n  )\\n  train_step = jax.jit(\\n      train_step,\\n      in_shardings=(var_sharding, data_sharding, data_sharding),\\n      out_shardings=(var_sharding, var_sharding),\\n  )\\n  return train_step\\n\\n\\ndef _TrainStep(\\n    state: TrainState,\\n    x: jnp.ndarray,\\n    y: jnp.ndarray,\\n    compute_loss_fn: Callable,  # pylint: disable=g-bare-generic\\n    learning_rate_fn: LearningRateSchedule,\\n    metrics_cls: Type[ClassifierTrainMetrics],\\n) -> tuple[TrainState, ClassifierTrainMetrics]:\\n  \"\"\"Single train step computes loss, gradients, and updates parameters.\"\"\"\\n  def _LossFn(params: Any) -> tuple[jnp.ndarray, Any]:\\n    logits, _ = state.apply_fn({\\'params\\': params}, x, mutable=[])\\n    return compute_loss_fn(logits, y), logits\\n\\n  (loss, logits), grads = jax.value_and_grad(_LossFn, has_aux=True)(\\n      state.params\\n  )\\n  grad = jax.lax.psum(grads, axis_name=\\'devices\\')\\n  new_state = state.apply_gradients(grads=grad)\\n  if len(y.shape) > 1:\\n    if y.shape[-1] > 1:\\n      labels = jnp.argmax(y, axis=-1, keepdims=False)\\n    else:\\n      labels = y.squeeze(-1)\\n  else:\\n    labels = y\\n  metrics_update = metrics_cls.gather_from_model_output(\\n      axis_name=\\'devices\\',\\n      labels=labels,\\n      logits=logits,\\n      loss=loss,\\n      learning_rate=learning_rate_fn(new_state.step),\\n  )\\n  return new_state, metrics_update\\n\\n\\ndef _BinaryCrossEntropyLoss(\\n    logits: jnp.ndarray, labels: jnp.ndarray\\n) -> jnp.ndarray:\\n  logits = jnp.clip(logits, 1e-12, 1.0 - 1e-12)\\n  binary_x_entropy = -jnp.log(logits) * labels\\n  binary_x_entropy -= jnp.log(1.0 - logits) * (1.0 - labels)\\n  return jnp.sum(binary_x_entropy)\\n\\n\\ndef _ClassifierEvalStep(\\n    state: TrainState,\\n    x: jnp.ndarray,\\n    y: jnp.ndarray,\\n) -> EvalMetrics:\\n  \"\"\"Single eval step computes loss and metrics.\"\"\"\\n  logits, _ = state.apply_fn({\\'params\\': state.params}, x, mutable=[])\\n  loss = _BinaryCrossEntropyLoss(logits, y)\\n  return state, EvalMetrics.gather_from_model_output(\\n      axis_name=\\'devices\\',\\n      labels=jnp.squeeze(y, -1),\\n      logits=logits,\\n      loss=loss,\\n  )\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6wKgs0U02BC",
        "outputId": "047d204b-c631-4458-c4f4-61d851d0b985"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model  model.py  __pycache__  sample_data  seqio_utils.py  train.py  train.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install seqio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G28O_AY11INF",
        "outputId": "60eecaaa-e9a5-4ff4-8f64-0c0657bbf559"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqio in /usr/local/lib/python3.11/dist-packages (0.0.19)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement xnlp (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for xnlp\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import ml_collections\n",
        "import jax\n",
        "\n",
        "import model\n",
        "import seqio_utils\n",
        "import train"
      ],
      "metadata": {
        "id": "xriFf07p0_rl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjztdCMe907u",
        "outputId": "a4a6ca80-8e48-4640-99e1-a29ba7480ab4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Run"
      ],
      "metadata": {
        "id": "pBJC2JpkFmVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = ml_collections.ConfigDict()\n",
        "config.seed = 42\n",
        "config.model_name = 'bytecode_transformer_functions'\n",
        "\n",
        "config.num_train_steps = 100\n",
        "config.initial_step = 1\n",
        "config.learning_rate = 1e-3\n",
        "config.lr_warmup_steps = 0\n",
        "config.lr_decay_steps = 0\n",
        "\n",
        "config.per_device_batch_size = 1\n",
        "config.train_tfrecord_path = 'train.tfrecord'\n",
        "config.max_vocab_size = 256 + 128\n",
        "config.seqlen = 2048\n",
        "\n",
        "config.log_loss_every_steps = 100\n",
        "config.eval_every_steps = 100\n",
        "\n",
        "config.num_layers = 1\n",
        "config.num_heads = 4\n",
        "config.embed_dim = 256\n",
        "config.transformer_mlp_dim = 512\n",
        "config.classifier_mlp_dim = 32\n",
        "# config.conv_layers = 1\n",
        "\n",
        "config.workdir = 'model'"
      ],
      "metadata": {
        "id": "kPmy06__9VMs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(filename='train.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
      ],
      "metadata": {
        "id": "0nveh5IuE7Yb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.TrainClassifier(config, allow_duplicate_tasks=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUYBIeD3BLtp",
        "outputId": "caa808e9-f704-467c-c07e-a00dbba75805"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:2025-04-08 20:27:13,217:jax._src.mesh_utils:82: Reordering mesh to physical ring order on single-tray TPU v2/v3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat train.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EiUu5oRErT6",
        "outputId": "e95d9901-a74f-444f-f71a-bd05e9c7c2cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-08 20:26:44,547 - INFO - Training with config: classifier_mlp_dim: 32\n",
            "embed_dim: 256\n",
            "eval_every_steps: 10\n",
            "initial_step: 1\n",
            "learning_rate: 0.001\n",
            "log_loss_every_steps: 10\n",
            "lr_decay_steps: 0\n",
            "lr_warmup_steps: 0\n",
            "max_vocab_size: 384\n",
            "model_name: bytecode_transformer_functions\n",
            "num_heads: 4\n",
            "num_layers: 1\n",
            "num_train_steps: 10\n",
            "per_device_batch_size: 1\n",
            "seed: 42\n",
            "seqlen: 2048\n",
            "train_tfrecord_path: train.tfrecord\n",
            "transformer_mlp_dim: 512\n",
            "workdir: model\n",
            "\n",
            "2025-04-08 20:26:44,549 - INFO - Device count: 8\n",
            "2025-04-08 20:26:44,549 - INFO - Using global batch size: 8\n",
            "2025-04-08 20:26:44,620 - INFO - Reordering mesh to physical ring order on single-tray TPU v2/v3.\n",
            "2025-04-08 20:26:44,621 - INFO - Using seed: 42\n",
            "2025-04-08 20:26:44,716 - INFO - Total parameters: 633665\n",
            "2025-04-08 20:26:44,719 - INFO - [Hyperparameters] {'classifier_mlp_dim': 32, 'embed_dim': 256, 'eval_every_steps': 10, 'initial_step': 1, 'learning_rate': 0.001, 'log_loss_every_steps': 10, 'lr_decay_steps': 0, 'lr_warmup_steps': 0, 'max_vocab_size': 384, 'model_name': 'bytecode_transformer_functions', 'num_heads': 4, 'num_layers': 1, 'num_train_steps': 10, 'per_device_batch_size': 1, 'seed': 42, 'seqlen': 2048, 'train_tfrecord_path': 'train.tfrecord', 'transformer_mlp_dim': 512, 'workdir': 'model'}\n",
            "2025-04-08 20:26:51,643 - INFO - Setting work unit notes: 2.6 steps/s, 100.0% (10/10), ETA: 0m\n",
            "2025-04-08 20:26:51,644 - INFO - [10] steps_per_sec=2.61691\n",
            "2025-04-08 20:26:51,644 - INFO - [10] uptime=6.9249\n",
            "2025-04-08 20:26:51,662 - INFO - [10] learning_rate=0.0010000000474974513, train_accuracy=0.8500000238418579, train_loss=0.6250201463699341, train_precision=0.0, train_recall=0.0, train_std=1.0729503631591797\n",
            "2025-04-08 20:27:13,148 - INFO - Training with config: classifier_mlp_dim: 32\n",
            "embed_dim: 256\n",
            "eval_every_steps: 100\n",
            "initial_step: 1\n",
            "learning_rate: 0.001\n",
            "log_loss_every_steps: 100\n",
            "lr_decay_steps: 0\n",
            "lr_warmup_steps: 0\n",
            "max_vocab_size: 384\n",
            "model_name: bytecode_transformer_functions\n",
            "num_heads: 4\n",
            "num_layers: 1\n",
            "num_train_steps: 100\n",
            "per_device_batch_size: 1\n",
            "seed: 42\n",
            "seqlen: 2048\n",
            "train_tfrecord_path: train.tfrecord\n",
            "transformer_mlp_dim: 512\n",
            "workdir: model\n",
            "\n",
            "2025-04-08 20:27:13,150 - INFO - Device count: 8\n",
            "2025-04-08 20:27:13,150 - INFO - Using global batch size: 8\n",
            "2025-04-08 20:27:13,217 - INFO - Reordering mesh to physical ring order on single-tray TPU v2/v3.\n",
            "2025-04-08 20:27:13,218 - INFO - Using seed: 42\n",
            "2025-04-08 20:27:13,312 - INFO - Total parameters: 633665\n",
            "2025-04-08 20:27:13,315 - INFO - [Hyperparameters] {'classifier_mlp_dim': 32, 'embed_dim': 256, 'eval_every_steps': 100, 'initial_step': 1, 'learning_rate': 0.001, 'log_loss_every_steps': 100, 'lr_decay_steps': 0, 'lr_warmup_steps': 0, 'max_vocab_size': 384, 'model_name': 'bytecode_transformer_functions', 'num_heads': 4, 'num_layers': 1, 'num_train_steps': 100, 'per_device_batch_size': 1, 'seed': 42, 'seqlen': 2048, 'train_tfrecord_path': 'train.tfrecord', 'transformer_mlp_dim': 512, 'workdir': 'model'}\n",
            "2025-04-08 20:27:21,568 - INFO - Setting work unit notes: 20.7 steps/s, 100.0% (100/100), ETA: 0m\n",
            "2025-04-08 20:27:21,569 - INFO - [100] steps_per_sec=20.7371\n",
            "2025-04-08 20:27:21,570 - INFO - [100] uptime=8.25397\n",
            "2025-04-08 20:27:21,586 - INFO - [100] learning_rate=0.0010000000474974513, train_accuracy=0.9099999666213989, train_loss=0.304015576839447, train_precision=0.5833333730697632, train_recall=0.09459459781646729, train_std=0.7591094970703125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configs for Experiments"
      ],
      "metadata": {
        "id": "cxFO_vDZFodQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Classification"
      ],
      "metadata": {
        "id": "yjyVaqX5Fp3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_examples = 28_080"
      ],
      "metadata": {
        "id": "q0Ppj-RQFz03"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "per_device_batch_size = batch_size // jax.local_device_count()\n",
        "n_epochs = 16\n",
        "train_steps = n_epochs * (n_examples // batch_size)\n",
        "log_loss_every_steps = train_steps // n_epochs  # Once per epoch\n",
        "eval_every_steps = train_steps #// n_epochs  # Once per epoch\n",
        "checkpoint_every_steps = train_steps // n_epochs"
      ],
      "metadata": {
        "id": "t3_5GQQuFn-m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p model"
      ],
      "metadata": {
        "id": "KX-QDp5PGJoq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = ml_collections.ConfigDict()\n",
        "config.seed = 42\n",
        "config.model_name = 'bytecode_transformer_functions'\n",
        "\n",
        "config.num_train_steps = train_steps\n",
        "config.initial_step = 1\n",
        "config.learning_rate = 1e-3\n",
        "config.lr_warmup_steps = 0\n",
        "config.lr_decay_steps = 0\n",
        "\n",
        "config.per_device_batch_size = per_device_batch_size\n",
        "config.train_tfrecord_path = '/path/to/train.trfrecord'\n",
        "config.test_tfrecord_path = '/path/to/test/test.tfrecord'\n",
        "config.max_vocab_size = 256 + 128\n",
        "config.seqlen = 2048\n",
        "\n",
        "config.log_loss_every_steps = log_loss_every_steps\n",
        "config.eval_every_steps = eval_every_steps\n",
        "\n",
        "config.checkpoint_every_steps = checkpoint_every_steps\n",
        "config.checkpoint_dir = '/path/to/ckpt_dir/'\n",
        "\n",
        "config.num_layers = 1\n",
        "config.num_heads = 4\n",
        "config.embed_dim = 256\n",
        "config.transformer_mlp_dim = 512\n",
        "config.classifier_mlp_dim = 32\n",
        "\n",
        "config.workdir = 'model'"
      ],
      "metadata": {
        "id": "ubi4_hVbF3mj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Script Classification"
      ],
      "metadata": {
        "id": "vF7dbfiqGMzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_examples_16k = 150891\n",
        "\n",
        "n_examples = n_examples_16k"
      ],
      "metadata": {
        "id": "3BGeKQg5GUwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "per_device_batch_size = batch_size // jax.local_device_count()\n",
        "n_epochs = 1\n",
        "train_steps = n_epochs * (n_examples // batch_size)\n",
        "log_loss_every_steps = train_steps // n_epochs # Once per epoch\n",
        "eval_every_steps = train_steps #// n_epochs  # Once per epoch\n",
        "checkpoint_every_steps = train_steps // n_epochs"
      ],
      "metadata": {
        "id": "1RplZm0SGWQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = ml_collections.ConfigDict()\n",
        "config.seed = 42\n",
        "config.model_name = 'bytecode_transformer_functions'\n",
        "\n",
        "config.num_train_steps = train_steps\n",
        "config.initial_step = 1\n",
        "config.learning_rate = 1e-3\n",
        "config.lr_warmup_steps = 0\n",
        "config.lr_decay_steps = 1.5 * train_steps\n",
        "\n",
        "config.per_device_batch_size = per_device_batch_size\n",
        "config.train_tfrecord_path = '/path/to/train.trfrecord'\n",
        "config.test_tfrecord_path = '/path/to/test/test.tfrecord'\n",
        "config.max_vocab_size = 256 + 128\n",
        "config.seqlen = 16_384\n",
        "\n",
        "config.log_loss_every_steps = log_loss_every_steps\n",
        "config.eval_every_steps = eval_every_steps\n",
        "\n",
        "config.checkpoint_every_steps = checkpoint_every_steps\n",
        "config.checkpoint_dir = '/path/to/ckpt_dir/'\n",
        "\n",
        "config.num_layers = 1\n",
        "config.num_heads = 4\n",
        "config.embed_dim = 256\n",
        "config.transformer_mlp_dim = 512\n",
        "config.classifier_mlp_dim = 32\n",
        "# Set to 1, 2\n",
        "# config.conv_blocks = 1\n",
        "\n",
        "config.workdir = 'model'"
      ],
      "metadata": {
        "id": "Ugosb8vqGOAc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}